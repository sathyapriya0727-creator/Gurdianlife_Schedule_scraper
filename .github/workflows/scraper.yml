name: Guardian Life Career Scraper

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Schedule: Monday, Wednesday, Friday at 8:00 AM IST = 2:30 AM UTC
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
on:
  schedule:
    - cron: '30 2 * * 1,3,5'

  # Run manually from GitHub â†’ Actions tab â†’ Run workflow
  workflow_dispatch:

jobs:
  scrape-jobs:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    permissions:
      contents: write   # Needed to push results back to repo

    steps:

      # 1. Check out the repository code
      - name: Checkout repository
        uses: actions/checkout@v4

      # 2. Set up Python 3.10
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      # 3. Cache pip packages (speeds up re-runs)
      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      # 4. Install Python dependencies
      - name: Install dependencies
        run: pip install -r requirements.txt

      # 5. Run the scraper
      - name: Run scraper
        run: python guardian_life_scraper_github.py

      # 6. Upload Excel artifact (download from Actions tab)
      - name: Upload Excel output
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: GuardianLife-Jobs-Excel-${{ github.run_id }}
          path: output/*.xlsx
          retention-days: 90

      # 7. Upload CSV artifact
      - name: Upload CSV output
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: GuardianLife-Jobs-CSV-${{ github.run_id }}
          path: output/*.csv
          retention-days: 90

      # 8. Upload log file
      - name: Upload scraper logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: Scraper-Logs-${{ github.run_id }}
          path: logs/
          retention-days: 30

      # 9. Commit and push output files back to the repository
      - name: Commit results to repository
        if: success()
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "GitHub Actions Bot"
          git add output/ logs/run_history.json 2>/dev/null || true
          git diff --staged --quiet || git commit -m "ðŸ¤– Auto-scrape: $(date +'%Y-%m-%d') â€” Guardian Life Jobs"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
